import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import joblib
import json
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import StackingClassifier
import xgboost as xgb


# Configuration de la page
st.set_page_config(
    page_title="Cybers√©curit√© avec NSL-KDD",
    page_icon="üîê",
    layout="wide"
)

# Style des titres
st.markdown("""
    <style>
    .title {
        color: #1F4E79;
        font-size: 60px;
        font-weight: bold;
        font-family: 'Arial', sans-serif;
    }
    .subtitle {
        color: #4682B4;
        font-size: 28px;
        font-weight: bold;
        margin-top: 20px;
    }
    .description {
        color: #000000;
        font-size: 20px;
        margin-top: 20px;
    }
    .chart-title {
        color: #1F4E79;
        font-size: 24px;
        font-weight: bold;
        text-align: center;
        margin-top: 20px;
    }
    .section-title {
        color: #1F4E79;
        font-size: 40px;
        font-weight: bold;
        margin-top: 40px;
        margin-bottom: 20px;
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)


# Introduction
st.markdown("""
# <span class='title'>NSL-KDD Insights: Analyse des Intrusions Cybern√©tiques üîê</span>

**Cette application d√©montre l'utilisation du machine learning pour am√©liorer la d√©tection des intrusions et la cybers√©curit√© √† l'aide du dataset NSL-KDD. Elle inclut une analyse des donn√©es via des visualisations et une d√©monstration de mod√®les de machine learning appliqu√©s aux donn√©es, vous trouverez un mini-tutoriel afin de savoir o√π surveiller et r√©cup√©rer vos donn√©es cyber en lien avec le dataset et afin de tester vos propres donn√©es dans notre mod√®le.**

## <span class='subtitle'>Contexte</span>
Les donn√©es du dataset NSL-KDD proviennent d'une version am√©lior√©e du dataset KDD'99, qui est lui-m√™me bas√© sur les donn√©es captur√©es lors de la comp√©tition DARPA 1998. Cette comp√©tition a √©t√© organis√©e par le MIT Lincoln Laboratory,  une agence du D√©partement de la D√©fense des √âtats-Unis, et visait √† √©valuer les syst√®mes de d√©tection d'intrusion (IDS). Les donn√©es de la comp√©tition DARPA 1998 incluent une large vari√©t√© de sc√©narios de trafic r√©seau, comprenant √† la fois des connexions normales et diverses attaques simul√©es.

Le dataset KDD'99 a √©t√© d√©riv√© de ces donn√©es, mais il pr√©sentait plusieurs probl√®mes comme des enregistrements redondants et des biais en faveur des enregistrements fr√©quents, ce qui a limit√© son efficacit√© pour l'√©valuation des IDS. Pour pallier ces limitations, le dataset NSL-KDD a √©t√© d√©velopp√© en 2009 par l'Universit√© du Nouveau-Brunswick, apportant des am√©liorations telles que la suppression des redondances et une meilleure distribution des niveaux de difficult√© des enregistrements.

En tant que benchmark, il aide √† am√©liorer la d√©tection des intrusions dans les syst√®mes modernes et sensibilise aux diff√©rents types d'attaques et leurs impacts.

Afin de faciliter son utilisation et d'am√©liorer la comparabilit√© des r√©sultats, le NSL-KDD est divis√© en 8 sous-ensembles de donn√©es, chacun ayant des caract√©ristiques sp√©cifiques.
Pour cette analyse, nous utilisons sp√©cifiquement les ensembles de donn√©es `KDDTrain+.TXT` et `KDDTest+.TXT`. 

- **KDDTrain+.TXT** : Utilis√© pour l'entra√Ænement de nos mod√®les et pour la partie visualisation.
- **KDDTest+.TXT** : Utilis√© pour tester nos mod√®les, ce dataset permet de v√©rifier la performance des mod√®les sur des donn√©es qui n'ont pas √©t√© vues lors de l'entra√Ænement.
""", unsafe_allow_html=True)

# Fonction st cache pour charger des donn√©es
@st.cache_data
def load_data(file_path):
    return pd.read_csv(file_path, encoding='ISO-8859-1')

# Afficher les donn√©es
def display_data(dataset_name, data):
    st.markdown(f"## Donn√©es du dataset {dataset_name}")
    st.write(data)

# Actions lorsque les boutons sont cliqu√©s
if st.button("Afficher KDDTrain+"):
    data_train = load_data('KDDTrain+.txt')
    display_data("KDDTrain+", data_train)

if st.button("Afficher KDDTest+"):
    data_test = load_data('KDDTest+.txt')
    display_data("KDDTest+", data_test)


# Chiffres Cl√©s en Cybers√©curit√©
st.markdown("""
## <span class='subtitle'>Chiffres cl√©s en Cybers√©curit√©</span>
- **2023** : Le co√ªt moyen d'une violation de donn√©es a atteint 4,24 millions de dollars.
- **2024** : On estime que les cyberattaques co√ªtent aux entreprises plus de 10,5 trillions de dollars par an.
- **√âconomie mondiale** : Les cyberattaques dans leur ensemble co√ªtent √† l'√©conomie mondiale plus de 6 000 milliards de dollars par an, selon une √©tude de Cybersecurity Ventures en 2021.
- **Temps de r√©cup√©ration** : Selon une enqu√™te de Radware en 2021, il faut en moyenne 23 jours pour se remettre d'une cyberattaque.
- **Attaques les plus fr√©quentes** : Phishing, Malware, Ransomware.

Bien que le NSL-KDD ne couvre pas sp√©cifiquement ces types d'attaques, il fournit une base solide pour comprendre et am√©liorer les syst√®mes de d√©tection d'intrusion, qui sont essentiels pour prot√©ger contre une vari√©t√© de menaces.
""", unsafe_allow_html=True)

# Types d'attaques dans NSL-KDD
st.markdown("""
## <span class='subtitle'>Types d'attaques repr√©sent√©es dans le NSL-KDD</span>

#### 1. DoS (Denial of Service)
- **Description** : Saturer un service pour le rendre indisponible.
- **Co√ªt global** : Les attaques DoS co√ªtent aux entreprises des milliards de dollars chaque ann√©e. Par exemple, une √©tude de Netscout en 2022 a estim√© que les attaques DoS pourraient co√ªter jusqu'√† 2,3 milliards de dollars par an.
- **Fr√©quence** : En 2021, Cloudflare a signal√© une augmentation de 125% des attaques DoS par rapport √† l'ann√©e pr√©c√©dente.
- **Exemple notable** : En 2016, l'attaque DDoS sur Dyn a caus√© des interruptions majeures sur des sites comme Twitter, Reddit et Netflix, affectant des millions d'utilisateurs.

#### 2. Probe
- **Description** : Tentative d'exploration pour d√©couvrir des vuln√©rabilit√©s.
- **Co√ªt global** : Bien que plus difficiles √† chiffrer, les attaques de type probe peuvent mener √† des intrusions plus graves. Elles sont souvent les pr√©misses d'attaques plus destructrices comme les DoS ou les compromissions de donn√©es.
- **Fr√©quence** : Les scans de ports, une forme courante de probe, sont tr√®s fr√©quents. Une √©tude de Palo Alto Networks en 2022 a r√©v√©l√© que 95% des organisations ont d√©tect√© des tentatives de scans de ports au moins une fois par mois.
- **Exemple notable** : En 2020, un scan massif de ports a √©t√© d√©tect√© ciblant des vuln√©rabilit√©s dans les syst√®mes de gestion de base de donn√©es comme MySQL et PostgreSQL. Cela a conduit √† des attaques de ransomware sur des entreprises telles que Cognizant et Travelex.

#### 3. U2R (User to Root)
- **Description** : L'utilisateur cherche √† obtenir des acc√®s root.
- **Co√ªt global** : Les attaques U2R sont particuli√®rement dangereuses car elles permettent √† un attaquant de prendre un contr√¥le total du syst√®me, potentiellement co√ªtant des millions en termes de pertes de donn√©es et de restauration.
- **Fr√©quence** : Bien que moins fr√©quentes que les DoS, ces attaques sont critiques en termes d'impact. Une √©tude de Verizon en 2021 a montr√© que les attaques U2R repr√©sentent environ 2% des attaques globales mais peuvent avoir des cons√©quences d√©vastatrices.
- **Exemple notable** : En 2019, l'attaque "Dirty COW" (CVE-2016-5195) a exploit√© une vuln√©rabilit√© dans le noyau Linux, permettant aux attaquants d'obtenir des privil√®ges root sur les syst√®mes affect√©s, compromettant des donn√©es telles que les informations d'identification des utilisateurs et les fichiers syst√®me.

#### 4. R2L (Remote to Local)
- **Description** : Tentative d'intrusion depuis une machine distante.
- **Co√ªt global** : Les attaques R2L peuvent entra√Æner des pertes financi√®res importantes. Une enqu√™te de Ponemon Institute en 2022 a estim√© que les violations de s√©curit√© co√ªtent en moyenne 4,24 millions de dollars par incident.
- **Fr√©quence** : Les attaques R2L sont courantes et constituent une menace persistante pour les organisations. Selon IBM, en 2021, environ 20% des cyberattaques sont de type R2L.
- **Exemple notable** : En 2021, une attaque R2L via une vuln√©rabilit√© dans Microsoft Exchange Server a permis aux attaquants d'acc√©der √† des syst√®mes internes, compromettant des informations sensibles telles que des donn√©es de correspondance confidentielle, des informations financi√®res et des donn√©es personnelles des employ√©s.
""", unsafe_allow_html=True)


# Titre de la section des graphiques
st.markdown("""
## <span class='section-title'>Dashboard des graphiques : Dashboard : visualisation et analyses des donn√©es (KDDTrain)</span>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    data_train = pd.read_csv('KDDTrain+.txt', encoding='ISO-8859-1')
    columns = (['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land',
                'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',
                'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files',
                'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',
                'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',
                'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',
                'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',
                'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',
                'attack', 'level'])
    data_train.columns = columns
    data_train['total_bytes'] = data_train['src_bytes'] + data_train['dst_bytes']
    return data_train

data_train = load_data()

# Fonction pour le mappage des attaques
def map_attack(attack):
    DoS = ['apache2', 'back', 'land', 'neptune', 'mailbomb', 'pod', 'processtable', 'smurf', 'teardrop', 'udpstorm', 'worm']
    Probe = ['ipsweep', 'mscan', 'nmap', 'portsweep', 'saint', 'satan']
    U2R = ['buffer_overflow', 'loadmodule', 'perl', 'ps', 'rootkit', 'sqlattack', 'xterm']
    R2L = ['ftp_write', 'guess_passwd', 'httptunnel',  'imap', 'multihop', 'named', 'phf', 'sendmail', 'snmpgetattack', 'spy',
           'snmpguess', 'warezclient', 'warezmaster', 'xlock', 'xsnoop']
    if attack in DoS:
        return "DoS"
    elif attack in Probe:
        return "Probe"
    elif attack in U2R:
        return "U2R"
    elif attack in R2L:
        return "R2L"
    else:
        return "Normal"

data_train['attack_category'] = data_train['attack'].apply(map_attack)


# R√©partition des attaques par classes
st.markdown("<h1 class='chart-title'>R√©partition des attaques par classes</h1>", unsafe_allow_html=True)
col1, col2 = st.columns([1, 2])
with col1:
    labels = ['Normal', 'DoS', 'Probe', 'R2L', 'U2R']
    sizes = [53.5, 36.5, 9.3, 0.8, 0.1]
    colors = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3', '#a6d854']
    explode = (0, 0, 0, 0.1, 0.3)  

    fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(aspect="equal"))

    # Trac√© du graphique en forme de donut
    wedges, texts, autotexts = ax.pie(
        sizes,
        explode=explode,
        labels=labels,
        colors=colors,
        autopct='%1.1f%%',
        startangle=140,
        wedgeprops=dict(width=0.3, edgecolor='w')
    )

    centre_circle = plt.Circle((0, 0), 0.70, fc='white')
    fig.gca().add_artist(centre_circle)

    plt.setp(autotexts, size=10, weight="bold")
    ax.legend(wedges, labels, title="Attack categories", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

    ax.set_title("Classification des attaques")

    st.pyplot(fig)
with col2:
    st.markdown("<span class='description'>Ce graphique montre la r√©partition des diff√©rentes classes d'attaques pr√©sentes dans le dataset NSL-KDD.</span>", unsafe_allow_html=True)
    st.markdown("<span class='description'>**Analyse** : Les connexions normales sont les plus fr√©quentes, suivies des attaques DoS puis probe. Les classes R2L et U2R sont particuli√®rement sous repr√©sent√©es malgr√© leur importance dans le spectre des cyberattaques, cel√† nous indique de possibles difficult√©s pour les mod√®les de machine learning √† d√©tecter ces intrusions. Cette r√©partition aide √† √©valuer la robustesse des syst√®mes de d√©tection d'intrusion (IDS) face √† des attaques vari√©es.</span>", unsafe_allow_html=True)


# R√©partition des types d'attaques
st.markdown("<h1 class='chart-title'>R√©partition des attaques par type</h1>", unsafe_allow_html=True)
col1, col2 = st.columns([1, 2])
with col1:
    abnormal_data = data_train[data_train['attack_category'] != 'Normal']

    attack_counts = abnormal_data['attack_category'].value_counts(normalize=True) * 100

    plt.style.use('ggplot')
    colors = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3']
    labels = attack_counts.index
    sizes = attack_counts.values
    explode = (0, 0, 0, 0.1)

    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(aspect="equal"))
    wedges, texts, autotexts = ax.pie(
        sizes,
        explode=explode,
        labels=labels,
        colors=colors,
        autopct='%1.1f%%',
        startangle=140,
        wedgeprops=dict(width=0.3, edgecolor='w')
    )

    centre_circle = plt.Circle((0, 0), 0.70, fc='white')
    fig.gca().add_artist(centre_circle)

    plt.setp(autotexts, size=10, weight="bold")
    ax.legend(wedges, labels, title="Attack categories", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
    ax.set_title("Proportion des attaques par type")
    st.pyplot(fig)
with col2:
    st.markdown("<span class='description'>Ce graphique circulaire montre la proportion des diff√©rents types d'attaques dans le dataset NSL-KDD.</span>", unsafe_allow_html=True)
    st.markdown("<span class='description'>**Analyse** : Le graphique r√©v√®le un fort d√©s√©quilibre des types d'attaques comme nous avons pu le voir plus haut, avec les attaques DoS repr√©sentant 78.3% des cas, suivies par les attaques Probe √† 19.9%. Les attaques R2L et U2R sont nettement moins fr√©quentes, √† 1.7% et 0.1% respectivement, soulignant la n√©cessit√© de m√©thodes de d√©tection capables de g√©rer ce d√©s√©quilibre.</span>", unsafe_allow_html=True)


# Distribution de la Dur√©e
st.markdown("<h1 class='chart-title'>Distribution de la Dur√©e</h1>", unsafe_allow_html=True)
col1, col2 = st.columns([1, 2])
with col1:
    fig_duration = plt.figure(figsize=(12, 6))
    sns.histplot(data_train['duration'], kde=True, color='blue')
    plt.title('Distribution de la Dur√©e')
    plt.xlabel('Dur√©e')
    plt.ylabel('Fr√©quence')
    st.pyplot(fig_duration)
with col2:
    st.markdown("<span class='description'>Ce graphique montre la distribution de la dur√©e des connexions enregistr√©es dans le dataset NSL-KDD. L'axe des x repr√©sente la dur√©e en secondes, tandis que l'axe des y repr√©sente la fr√©quence de chaque dur√©e.</span>", unsafe_allow_html=True)
    st.markdown("<span class='description'>**Analyse** : La majorit√© des connexions ont une dur√©e tr√®s courte, typique des datasets de trafic r√©seau. Quelques connexions avec des dur√©es exceptionnellement longues peuvent indiquer des activit√©s suspectes.</span>", unsafe_allow_html=True)

# Distribution des Taux d'erreur de serveur par protocole
st.markdown("<h1 class='chart-title'>Distribution des taux d'erreur de serveur par Protocole</h1>", unsafe_allow_html=True)
col1, col2 = st.columns([1, 2])
with col1:
    fig_error_rate = plt.figure(figsize=(12, 6))
    sns.violinplot(x='protocol_type', y='serror_rate', data=data_train, palette='Set3')
    plt.title('Distribution des taux d\'erreur de serveur par protocole')
    plt.xlabel('Type de protocole')
    plt.ylabel('Taux d\'erreur de serveur')
    st.pyplot(fig_error_rate)
with col2:
    st.markdown("<span class='description'>Ce graphique montre la distribution des taux d'erreur de serveur (serror_rate) par type de protocole utilis√© dans les connexions (TCP, ICMP, UDP).</span>", unsafe_allow_html=True)
    st.markdown("<span class='description'>**Analyse** : Les connexions TCP montrent des taux d'erreur vari√©s, ce qui peut refl√©ter des sc√©narios o√π les connexions TCP r√©ussissent ou √©chouent compl√®tement. Les erreurs de serveur √©lev√©es dans les connexions TCP peuvent indiquer des tentatives de manipulation de paquets ou des attaques visant √† provoquer des erreurs de traitement sur les serveurs, telles que les attaques de type buffer overflow. Les connexions ICMP n'ont pas d'erreurs de serveur, ce qui est coh√©rent avec leur utilisation principalement pour des diagnostics r√©seau. Les connexions UDP montrent √©galement des variations dans les taux d'erreur, souvent associ√©es √† des attaques DoS, ce qui souligne l'importance de surveiller les erreurs de serveur pour ces protocoles afin de d√©tecter rapidement les activit√©s suspectes.</span>", unsafe_allow_html=True)

# Comptes de services de destination les plus utilis√©s par type d'attaque
st.markdown("<h1 class='chart-title'>Comptes de services de destination les plus utilis√©s par type d'attaque</h1>", unsafe_allow_html=True)
col1, col2 = st.columns([1, 2])
with col1:
    fig_services_by_attack, ax = plt.subplots(figsize=(14, 8))
    attack_srv_count = data_train.groupby(['attack', 'dst_host_srv_count']).size().unstack(fill_value=0)
    top_srv_counts = data_train['dst_host_srv_count'].value_counts().index[:10]
    filtered_attack_srv_count = attack_srv_count[top_srv_counts]
    filtered_attack_srv_count.plot(kind='bar', stacked=True, ax=ax, colormap='tab20')
    ax.set_title('Comptes de services de destination les plus utilis√©s par type d\'attaque')
    ax.set_xlabel('Type d\'attaque')
    ax.set_ylabel('Nombre d\'observations')
    st.pyplot(fig_services_by_attack)
with col2:
    st.markdown("<span class='description'>Ce graphique montre les services de destination les plus utilis√©s pour chaque type d'attaque. Les barres empil√©es permettent de visualiser la r√©partition des services parmi diff√©rents types d'attaques.</span>", unsafe_allow_html=True)
    st.markdown("<span class='description'>**Analyse** : Le service avec le compte 255 pr√©domine, notamment pour les connexions normales, indiquant une forte concentration d'activit√©s r√©seau r√©guli√®res vers ce service. Les attaques, en revanche, ciblent une gamme plus diversifi√©e de services, soulignant que les attaquants visent diff√©rents services pour maximiser l'impact. Les attaques DoS et Probe montrent une diversit√© de cibles, tandis que les attaques R2L et U2R sont associ√©es √† des comptes de services moins fr√©quents, indiquant des tentatives plus cibl√©es. La concentration √©lev√©e sur le service 255 pour certaines attaques, comme neptune, souligne des tentatives de saturation sp√©cifiques.</span>", unsafe_allow_html=True)

# R√©partition des Flags
st.markdown("<h1 class='chart-title'>R√©partition des Flags</h1>", unsafe_allow_html=True)
col1, col2 = st.columns([1, 2])
with col1:
    fig_flags = plt.figure(figsize=(12, 6))
    sns.countplot(x='flag', data=data_train, palette='Set1')
    plt.title('R√©partition des Flags')
    plt.xlabel('Flag')
    plt.ylabel('Nombre d\'observations')
    st.pyplot(fig_flags)
with col2:
    st.markdown("<span class='description'>Ce graphique montre la r√©partition des diff√©rents flags dans le dataset NSL-KDD. Les flags sont des indicateurs de l'√©tat des connexions TCP.</span>", unsafe_allow_html=True)
    st.markdown("<span class='description'>**Analyse** : Le flag SF est le plus fr√©quent, indiquant des connexions r√©ussies. Les flags S0 et REJ sont courants dans les scans de port et les tentatives d'intrusion, respectivement.</span>", unsafe_allow_html=True)


# Distribution des Total Bytes par type d'Attaque
st.markdown("<h1 class='chart-title'>Distribution des Total Bytes par type d'attaque</h1>", unsafe_allow_html=True)
col1, col2 = st.columns([1, 2])
with col1:
    fig_total_bytes = plt.figure(figsize=(12, 6))
    data_train['log_total_bytes'] = np.log1p(data_train['total_bytes'])
    sns.violinplot(x='attack', y='log_total_bytes', data=data_train, scale='width', inner='quartile', palette='Set2')
    plt.title('Distribution des total Bytes par type d\'attaque')
    plt.xlabel('Type d\'attaque')
    plt.ylabel('Log Total Bytes')
    plt.xticks(rotation=90)
    st.pyplot(fig_total_bytes)
with col2:
    st.markdown("<span class='description'>Ce graphique en violon montre la distribution des total bytes (total d'octets transf√©r√©s) pour chaque type d'attaque, en utilisant une √©chelle logarithmique pour mieux visualiser les diff√©rences.</span>", unsafe_allow_html=True)
    st.markdown("<span class='description'>**Analyse** : Certaines attaques, comme `portsweep` et `warezmaster`, ont une distribution large des total bytes, indiquant des variations significatives dans le volume de donn√©es transf√©r√©es. Cela peut indiquer des tentatives de reconnaissance extensive ou de vol de donn√©es. Les attaques `neptune` et `smurf` montrent une distribution plus concentr√©e, typique des attaques DoS visant √† saturer les ressources avec un volume √©lev√© de paquets similaires. La surveillance des variations dans les total bytes peut aider √† identifier des comportements anormaux et √† distinguer les types d'attaques bas√©es sur les mod√®les de transfert de donn√©es.</span>", unsafe_allow_html=True)

# Matrice de Corr√©lation
st.markdown("<h1 class='chart-title'>Matrice de Corr√©lation</h1>", unsafe_allow_html=True)
col1, col2 = st.columns([1, 2])
with col1:
    fig_corr_matrix = plt.figure(figsize=(12, 10))
    numerical_data = data_train.select_dtypes(include=[np.number])
    correlation_matrix = numerical_data.corr()
    sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=".2f")
    plt.title('Matrice de corr√©lation')
    st.pyplot(fig_corr_matrix)
st.markdown("<br><br>", unsafe_allow_html=True)
with col2:
    st.markdown("<span class='description'>Cette matrice de corr√©lation montre les relations entre diff√©rentes caract√©ristiques du dataset NSL-KDD. Les valeurs de corr√©lation varient de -1 (corr√©lation n√©gative forte) √† 1 (corr√©lation positive forte), autour de 0 (il n'y pas de corr√©lation donc on aura tendance √† ne pas conserver ces variables).</span>", unsafe_allow_html=True)
    st.markdown("<span class='description'>**Analyse** : Certaines caract√©ristiques montrent des corr√©lations fortes, comme `count` et `srv_count`, indiquant qu'elles varient ensemble de mani√®re significative. Les corr√©lations faibles ou n√©gatives sugg√®rent une relation inverse ou une ind√©pendance. Des corr√©lations trop fortes entre certaines variables peuvent perturber le mod√®le de machine learning en introduisant de la redondance et en augmentant le risque de surajustement. Il est crucial d'√©tudier ces corr√©lations pour s√©lectionner les variables √† inclure dans le mod√®le. Par exemple, combiner ou √©liminer des variables hautement corr√©l√©es peut simplifier le mod√®le et am√©liorer sa performance.</span>", unsafe_allow_html=True)


# Synth√®se Finale graph

st.markdown("""
<h2 style='color: #1F4E79;'>Conclusion</h2>

<h3 style='color: #4682B4;'>Analyse du dashboard et implications pour la Cybers√©curit√©</h3>

<span class='description'>
Les graphiques r√©v√®lent plusieurs tendances cruciales pour la cybers√©curit√© : 


**La pr√©dominance des attaques DoS**, qui repr√©sentent 78.3% des incidents, indique que **les entreprises doivent renforcer leurs d√©fenses contre ces attaques massives** qui saturent les ressources des services. 
En parall√®le, les scans de ports (attacks Probe) montrent une diversit√© dans les services cibl√©s, ce qui sugg√®re la n√©cessit√© de surveiller attentivement les tentatives d'acc√®s aux services vari√©s pour pr√©venir les intrusions.

La corr√©lation √©lev√©e entre certaines caract√©ristiques, comme le taux d'erreur de serveur et les attaques DoS, souligne **l'importance de surveiller les erreurs fr√©quentes** pour d√©tecter rapidement les activit√©s suspectes. 
De plus, *les flags TCP comme S0 et REJ sont indicateurs de tentatives de scans de port* et d'intrusions, respectivement, n√©cessitant une attention particuli√®re √† ces √©tats de connexion pour une d√©tection pr√©coce.

L'analyse des total bytes transf√©r√©s et des dur√©es de connexion offre des perspectives suppl√©mentaires. 
Les attaques comme `portsweep` et `warezmaster` montrent une large variation de donn√©es transf√©r√©es, soulignant l'importance de surveiller les comportements de transfert de donn√©es pour identifier les activit√©s anormales. 
Enfin, **la dur√©e des connexions, souvent plus courte pour les connexions normales**, peut aider √† distinguer les activit√©s malveillantes de celles l√©gitimes.

La r√©partition des services de destination les plus utilis√©s montre que **certains services sont particuli√®rement vuln√©rables et fr√©quemment cibl√©s**.
 Une attention particuli√®re doit √™tre port√©e aux services couramment utilis√©s comme **HTTP et FZZ**, qui sont souvent exploit√©s par des attaquants.

**Recommandations Cl√©s**:
- **Renforcer les D√©fenses Contre les DoS** : Mettez en place des syst√®mes robustes pour pr√©venir les saturations de ressources et les interruptions de service.
- **Surveillance des Ports** : Surveillez attentivement les tentatives d'acc√®s aux services vari√©s et configurez des r√®gles de pare-feu pr√©cises pour pr√©venir les intrusions.
- **D√©tection Pr√©coce** : Utilisez les erreurs de serveur et les flags TCP comme indicateurs pour rep√©rer rapidement les comportements suspects.
- **Analyse des Transferts de Donn√©es** : Surveillez les volumes de donn√©es transf√©r√©es pour identifier les activit√©s anormales, notamment celles avec de larges variations.
- **Protection des Services Vuln√©rables** : Renforcez la s√©curit√© des services fr√©quemment cibl√©s, comme HTTP et FTP, pour r√©duire les risques d'exploitation.

En conclusion, ces analyses offrent une compr√©hension d√©taill√©e des comportements des intrusions et des vuln√©rabilit√©s du r√©seau et nous donne des pistes pour se pr√©venir du mieux possible face aux cyber-intrusions.
</span>
""", unsafe_allow_html=True)

# Titre de la section de Machine learning
st.markdown("""
## <span class='section-title'> Machine Learning appliqu√© au NSL-KDD</span>
""", unsafe_allow_html=True)

st.markdown("""
## <span class='subtitle'>Choix des m√©triques √† observer</span>

Dans le contexte de l'analyse du dataset NSL-KDD pour la d√©tection d'intrusions, il est crucial de prioriser la r√©duction des faux n√©gatifs (FN) avant celle des faux positifs (FP). Les faux n√©gatifs repr√©sentent les intrusions qui ne sont pas d√©tect√©es et, par cons√©quent, laissent le syst√®me vuln√©rable aux attaques. Une intrusion non d√©tect√©e peut entra√Æner des pertes importantes de donn√©es, des compromissions de s√©curit√© et des dommages consid√©rables aux infrastructures.

Ensuite, bien que les faux positifs puissent entra√Æner des alertes superflues et une charge de travail accrue pour les analystes, leur impact est g√©n√©ralement moins s√©v√®re que celui des intrusions non d√©tect√©es.

C'est pourquoi nous nous concentrons sur des m√©triques telles que le recall pour minimiser les faux n√©gatifs, tout en surveillant la pr√©cision pour g√©rer les faux positifs. Une attention particuli√®re est √©galement port√©e aux autres m√©triques pour assurer un √©quilibre global entre la sensibilit√© et la sp√©cificit√© du mod√®le.
""", unsafe_allow_html=True)


st.markdown("""
## <span class='subtitle'>Tests et choix du Mod√®le pour la d√©tection d'intrusion </span>

Pour l'analyse du dataset NSL-KDD, nous avons test√© une vari√©t√© de mod√®les de machine learning, incluant des mod√®les supervis√©s, non supervis√©s, et des approches de deep learning. La difficult√© principale √©tait de lutter contre le surapprentissage 
(la difficult√© du mod√®le √† g√©n√©raliser sur de nouvelles donn√©es) probablement due au d√©s√©quilibre des √©chantillons de donn√©es pour les types d'attaques.

### <span class='chart-title'>Mod√®les de Machine Learning Supervis√©</span>
Nous avons exp√©riment√© avec plusieurs algorithmes de machine learning supervis√©, tels que :
- **R√©gression Logistique**
- **Arbre de D√©cision**
- **Random Forest**
- **SVM (Support Vector Machine)**
- **AdaBoost**
- **XGBoost**
- **LightGBM**

Le mod√®le XGBoost pr√©sente les meilleures performance pour les mod√®les supervis√©. Le mod√®le de stacking avec XGBoost en m√©tat apprenan est √©galement tr√®s correct (meilleure pr√©cision mais moins bon recall).

Le XGboost s'est d√©marqu√© pour ses r√©sultats au niveau du recall.

### <span class='chart-title'>Mod√®les de Deep Learning</span>
Les architectures de deep learning test√©es incluent :
- **CNN (Convolutional Neural Network)**
- **RNN (Recurrent Neural Network)**
- **FNN (Feedforward Neural Network)**
- **ANN (Artificial Neural Network)**

Le mod√®le ANN a montr√© les meilleures performances parmi les mod√®les de deep learning.

### <span class='chart-title'>Mod√®les Non Supervis√©s</span>
Pour la d√©tection de patterns sans labels nous avons utilis√© le - **KNN (K-Nearest Neighbors)**

### <span class='chart-title'>Pr√©traitement des Donn√©es</span>
Le pr√©traitement des donn√©es a inclus plusieurs √©tapes essentielles :
- **Regroupement des Bytes** : Combinaison des bytes source et destination pour obtenir une m√©trique de total bytes.
- **S√©lection des Features Pertinentes** : Analyse de corr√©lation pour identifier et r√©duire la dimensionnalit√©, utilisation d'un algorithme de selection des meilleures features selon leur score .
- **√âquilibrage des Classes** : Utilisation de SMOTE pour √©quilibrer les classes.

### <span class='chart-title'>Techniques pour Combattre l'Overfitting</span>
Pour am√©liorer la robustesse des mod√®les, nous avons utilis√© :
- **R√©gularisation (L2)** : Appliqu√©e dans les mod√®les de r√©gression et de SVM pour p√©naliser les coefficients excessifs.
- **Validation Crois√©e** : k-fold cross-validation pour √©valuer la performance de mani√®re fiable.
- **Ensemble Methods** : Utilisation de Random Forest, AdaBoost et LightGBM pour une meilleure g√©n√©ralisation.


### <span class='chart-title'>R√©sultats des mod√®les</span>
""", unsafe_allow_html=True)

# Les r√©sultats des mod√®les
models = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM', 'XGBoost', 'LightGBM', 'AdaBoost', 'KNN', 'FNN', 'CNN', 'RNN', 'ANN', 'Stacking Model']

train_precision = [0.969, 0.999983, 0.999436, 0.994663, 0.992518, 0.999897, 0.999941, 0.997815, 0.994651, 0.994609, 0.993457, 0.994189, 0.9997624562028624]
test_precision = [0.910395, 0.961298, 0.966502, 0.953568, 0.923894, 0.967510, 0.961721, 0.918346, 0.967621, 0.965690, 0.921890, 0.951030, 0.9613342566943675]

train_recall = [0.952908, 0.999898, 0.997356, 0.993511, 0.996748, 1.0, 0.999955, 0.997083, 0.989459, 0.994303, 0.984035, 0.992154, 0.9999703008523655]
test_recall = [0.558993, 0.634897, 0.595854, 0.611362, 0.670745, 0.608106, 0.601075, 0.621415, 0.605517, 0.631702, 0.586814, 0.647756, 0.6490804239401496]

# Cr√©ation du graphique
col1, col2 = st.columns([1, 2])
with col1:
    fig, ax = plt.subplots(figsize=(14, 8))

    # Pr√©cision
    ax.plot(models, train_precision, marker='o', linestyle='-', color='blue', label='Train Precision')
    ax.plot(models, test_precision, marker='o', linestyle='-', color='green', label='Test Precision')

    # Rappel
    ax.plot(models, train_recall, marker='o', linestyle='-', color='pink', label='Train Recall')
    ax.plot(models, test_recall, marker='o', linestyle='-', color='red', label='Test Recall')

    ax.set_xlabel('Mod√®les')
    ax.set_ylabel('Score')
    ax.set_title('Comparaison des Pr√©cisions et Recalls des mod√®les')
    ax.set_xticklabels(models, rotation=45)
    ax.legend()
    ax.grid(True)
    plt.tight_layout()

    st.pyplot(fig)

# Choix du mod√®le final
st.markdown("""
## <span class='subtitle'>Choix du mod√®le final : Mod√®le XGBoost</span>

Apr√®s √©valuation, nous avons opt√© pour une approche de **XGBoost** en utilisant la m√©thode SMOTE. Ce mod√®le offre une pr√©diction √©quilibr√© et le meilleur recall, notre choix ce porte donc vers lui pour √©viter au maximum les faux n√©gatifs lors de l'adaptation du mod√®le √† des donn√©es r√©elles.


**Vous pouvez tester le mod√®le dans la partie "Simulation", les features avec des donn√©es non saisies seront automatiquement remplies par la valeur m√©diane observ√©e dans le Data_train.**

**Si vous ne savez pas o√π trouver vos donn√©es de cybers√©curit√© vous pouvez suivre le mini-tutoriel ci dessous en cliquant dessus. Il a √©t√© cr√©e afin d'observer de comprendre et de collecter les donn√©es en liens avec les 12 features les plus importantes du NSL-KDD.**
""", unsafe_allow_html=True)

# Section de tutoriel cach√©e 
with st.expander("Mini Tutoriel : Acc√©der aux Logs r√©seau et entr√©es pour voir ses information de cybers√©curit√©"):
    st.markdown("""
    ### Qu'est-ce qu'un log r√©seau ?
    Un log r√©seau est un fichier ou une base de donn√©es qui enregistre les activit√©s du r√©seau. Cela inclut des informations sur les connexions √©tablies, les tentatives de connexion √©chou√©es, les volumes de donn√©es transf√©r√©es, etc. Ces logs sont g√©n√©ralement g√©n√©r√©s par des dispositifs r√©seau tels que les routeurs, les pare-feu, et les serveurs.
    
    ### O√π trouver les logs ?
    Les logs r√©seau sont souvent stock√©s sur les dispositifs r√©seau eux-m√™mes ou sur des serveurs de log centralis√©s. Voici comment acc√©der aux logs sur des dispositifs courants :
    
    **Routeurs et Pare-feu :**
    
    **Acc√®s via l'interface web :**
    
    1. Ouvrez votre navigateur web.
    2. Entrez l'adresse IP du routeur ou du pare-feu (souvent quelque chose comme 192.168.1.1 ou 192.168.0.1).
    3. Connectez-vous avec vos identifiants administrateur.
    4. Recherchez une section appel√©e "Logs", "Journal", "Syslog" ou "Rapports".
    5. Vous pourrez g√©n√©ralement voir et t√©l√©charger les logs r√©seau.
    
    **Acc√®s via SSH :**
    
    1. Utilisez un client SSH (comme PuTTY) pour vous connecter au dispositif.
    2. Entrez l'adresse IP du dispositif et vos identifiants administrateur.
    3. Utilisez des commandes sp√©cifiques au dispositif pour afficher les logs (par exemple, `show log` sur certains routeurs).
    
    **Serveurs :**
    
    **Sous Windows :**
    
    1. Ouvrez l'Observateur d'√©v√©nements (`eventvwr.msc`).
    2. Allez dans Journaux des applications et des services > Microsoft > Windows > Diagnostics-Performance > Op√©rationnel.
    3. Recherchez les √©v√©nements li√©s au r√©seau.
    
    **Sous Linux et macOS :**
    
    1. Ouvrez un terminal.
    2. Acc√©dez aux logs dans `/var/log` (par exemple, `cd /var/log`).
    3. Utilisez `cat`, `less` ou `grep` pour visualiser les logs, par exemple :
    ```bash
    cat /var/log/syslog | grep "network"
    ```
    
    **Syst√®mes de gestion de Logs centralis√©s :**
    
    - Exemples de syst√®mes : Splunk, ELK Stack (Elasticsearch, Logstash, Kibana), Graylog.
    - Connectez-vous √† l'interface web de votre syst√®me de gestion de logs.
    - Utilisez les fonctionnalit√©s de recherche et de filtrage pour trouver les informations r√©seau.
    """)

    st.markdown("""
    ### Guide pour acc√©der √† ses principales informations de s√©curit√©
    
    **Duration (duration) : La dur√©e d'une connexion**
    
    - **Description :** La dur√©e totale en secondes pendant laquelle une connexion r√©seau a √©t√© √©tablie.
    - **O√π la trouver :** Cette information peut √™tre trouv√©e dans les journaux de connexion ou les fichiers de log de votre pare-feu ou de votre routeur.
    - **Comment l'obtenir :** Recherchez dans les logs des entr√©es contenant des informations sur le d√©but et la fin des connexions. Soustrayez ces valeurs pour obtenir la dur√©e.
    - **Exemple :** Si les logs indiquent start_time=10:00 et end_time=10:05, la dur√©e est de 300 secondes.
    
    **Protocol Type (protocol_type) : Le protocole utilis√© (TCP, UDP, ICMP)**
    
    - **Description :** Le type de protocole de communication utilis√© par la connexion r√©seau.
    - **O√π la trouver :** G√©n√©ralement disponible dans les journaux de connexion ou les rapports de trafic r√©seau.
    - **Comment l'obtenir :** Les logs mentionnent souvent le type de protocole utilis√© pour chaque connexion.
    - **Exemple :** Recherchez des entr√©es telles que protocol=TCP, protocol=UDP, ou protocol=ICMP.
    
    **Service (service) : Le service de destination (HTTP, FTP, SMTP, etc.)**
    
    - **Description :** Le service r√©seau auquel la connexion √©tait destin√©e.
    - **O√π la trouver :** Souvent indiqu√© dans les journaux de pare-feu ou les logs des serveurs.
    - **Comment l'obtenir :** Les logs indiquent souvent le service de destination pour chaque connexion.
    - **Exemple :** Recherchez des entr√©es telles que service=HTTP, service=FTP, ou service=SMTP.
    
    **Number of Failed Logins (num_failed_logins) : Le nombre de tentatives de connexion √©chou√©es**
    
    - **Description :** Le nombre de tentatives de connexion infructueuses avant la connexion r√©ussie.
    - **O√π la trouver :** Disponible dans les journaux d'authentification ou les fichiers de log de s√©curit√©.
    - **Comment l'obtenir :** Les journaux d'authentification ou de s√©curit√© enregistrent les tentatives de connexion √©chou√©es.
    - **Exemple :** Recherchez des entr√©es telles que failed login attempts=3.
    
    **Count (count) : Le nombre de connexions au m√™me h√¥te**
    
    - **Description :** Le nombre de connexions √©tablies au m√™me h√¥te pendant une p√©riode donn√©e.
    - **O√π la trouver :** Visible dans les journaux de connexion ou les rapports d'analyse de trafic.
    - **Comment l'obtenir :** Comptez le nombre de connexions au m√™me h√¥te dans une p√©riode donn√©e en utilisant les logs de connexion.
    - **Exemple :** Si les logs montrent 5 connexions distinctes au m√™me h√¥te en une heure, le count est 5.
    
    **Bytes envoy√©s et re√ßus (total_bytes) : Le volume de donn√©es √©chang√©es**
    
    - **Description :** La somme des octets envoy√©s et re√ßus pendant la connexion.
    - **O√π la trouver :** Dans les logs de connexion r√©seau ou les outils de surveillance de bande passante.
    - **Comment l'obtenir :** Additionnez les octets envoy√©s (src_bytes) et re√ßus (dst_bytes) pour chaque connexion.
    - **Exemple :** Si src_bytes=1000 et dst_bytes=2000, alors total_bytes=3000.
    
    **√âtat de connexion (logged_in) : Indique si la connexion a r√©ussi ou non**
    
    - **Description :** Indique si la connexion a √©t√© r√©ussie (1) ou √©chou√©e (0).
    - **O√π la trouver :** Dans les journaux d'authentification ou les rapports de connexion.
    - **Comment l'obtenir :** Les journaux d'authentification indiquent souvent si la connexion a r√©ussi ou non.
    - **Exemple :** Recherchez des entr√©es comme login successful=1 ou login failed=0.
    
    **Dst Host Same Src Port Rate (dst_host_same_src_port_rate) : Le taux de connexions au m√™me port source**
    
    - **Description :** Le pourcentage de connexions au m√™me port source sur l'h√¥te de destination.
    - **O√π la trouver :** N√©cessite une analyse des logs de connexion pour calculer cette m√©trique.
    - **Comment l'obtenir :** Calculez le pourcentage de connexions utilisant le m√™me port source sur l'h√¥te de destination √† partir des logs de connexion.
    - **Exemple :** Si sur 10 connexions, 7 utilisent le m√™me port source, le taux est de 70%.
    
    ### Variables Moins Accessibles (Pour Information)
    
    **Srv Count (srv_count)**
    
    - **Description :** Le nombre de connexions au m√™me service.
    - **O√π la trouver :** Dans les logs de service ou les rapports d'analyse de trafic.
    
    **Flag (flag)**
    
    - **Description :** Indique l'√©tat de la connexion TCP (par exemple, S0, REJ).
    - **O√π la trouver :** Dans les logs de connexion TCP/IP.
    
    **Serror Rate (serror_rate) : Le taux d'erreurs de serveur**
    
    - **Description :** Le pourcentage de connexions ayant des erreurs de serveur.
    - **O√π la trouver :** N√©cessite une analyse des logs de connexion pour calculer cette m√©trique.
    
    **Rerror Rate (rerror_rate) : Le taux d'erreurs de r√©ponse**
    
    - **Description :** Le pourcentage de connexions ayant des erreurs de r√©ponse.
    - **O√π la trouver :** N√©cessite une analyse des logs de connexion pour calculer cette m√©trique.
    """)

    st.markdown("""
    ### Exemple de Journal de connexion
    
    Voici un exemple de ce √† quoi peuvent ressembler les entr√©es de log :
    
    ```
    timestamp="2023-06-15T10:00:00Z" protocol="TCP" service="HTTP" src_bytes=500 dst_bytes=1500 duration=60 logged_in=1
    timestamp="2023-06-15T10:05:00Z" protocol="UDP" service="DNS" src_bytes=200 dst_bytes=300 duration=5 logged_in=0

        ```
    
    """)
    
    
# Pr√©paration du mod√®le, 


# Charger les donn√©es et calculer les m√©dianes
@st.cache_data
def load_training_data():
    data_train = pd.read_csv('KDDTrain+.txt', encoding='ISO-8859-1')
    columns = (['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land',
                'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',
                'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files',
                'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',
                'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',
                'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',
                'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',
                'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',
                'attack', 'level'])
    data_train.columns = columns
    data_train['total_bytes'] = data_train['src_bytes'] + data_train['dst_bytes']
    return data_train

data_train = load_training_data()

# Calculer les m√©dianes des colonnes num√©riques 
numeric_columns = data_train.select_dtypes(include=['number']).columns
medians = data_train[numeric_columns].median()

# D√©finir les valeurs par d√©faut 
default_values = {
    "num_failed_logins": medians['num_failed_logins'],
    "dst_host_srv_serror_rate": medians['dst_host_srv_serror_rate'],
    "count": medians['count'],
    "serror_rate": medians['serror_rate'],
    "dst_host_diff_srv_rate": medians['dst_host_diff_srv_rate'],
    "dst_host_serror_rate": medians['dst_host_serror_rate'],
    "diff_srv_rate": medians['diff_srv_rate'],
    "dst_host_same_src_port_rate": medians['dst_host_same_src_port_rate'],
    "dst_host_count": medians['dst_host_count'],
    "dst_host_srv_diff_host_rate": medians['dst_host_srv_diff_host_rate'],
    "duration": medians['duration'],
    "total_bytes": medians['total_bytes'],
    "logged_in": medians['logged_in'],
    "land": medians['land'],
    "hot": medians['hot'],
    "same_srv_rate": medians['same_srv_rate'],
    "dst_host_srv_count": medians['dst_host_srv_count'],
    "wrong_fragment": medians['wrong_fragment'],
    "su_attempted": medians['su_attempted'],
    "protocol_type": "tcp",  
    "flag": "SF",
    "service": "http"
}

# Encoder
@st.cache_data
def fit_encoder(data):
    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    encoder.fit(data[['protocol_type', 'flag', 'service']])
    return encoder

encoder = fit_encoder(data_train)

# Pr√©paration du scaler √† partir des donn√©es d'entra√Ænement
@st.cache_data
def fit_scaler(data):
    scaler = StandardScaler()
    data_scaled = scaler.fit(data)
    return scaler

scaler = fit_scaler(data_train)

# Charger le mod√®le
model = joblib.load('modelXGboost1.pkl')

# Fonction de pr√©traitement
def preprocess_data(data, scaler, encoder):
    selected_features = ['num_failed_logins', 'dst_host_srv_serror_rate', 'count', 'serror_rate', 'dst_host_diff_srv_rate',
                         'dst_host_serror_rate', 'diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_count',
                         'dst_host_srv_diff_host_rate', 'duration', 'total_bytes', 'logged_in', 'land', 'hot',
                         'same_srv_rate', 'dst_host_srv_count', 'wrong_fragment', 'su_attempted']
    data_scaled = pd.DataFrame([data])[selected_features]

    data_scaled = scaler.transform(data_scaled)

    encoded_features = encoder.transform(pd.DataFrame([data])[['protocol_type', 'flag', 'service']])
    encoded_columns = encoder.get_feature_names_out(['protocol_type', 'flag', 'service'])

    data_scaled_df = pd.DataFrame(data_scaled, columns=selected_features)
    encoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)

    X = pd.concat([data_scaled_df, encoded_df], axis=1)

    return X

# Fonction de pr√©diction
def make_prediction(data, scaler, encoder, model):
    X = preprocess_data(data, scaler, encoder)
    predictions = model.predict(X)
    return predictions

# Interface utilisateur
st.title('D√©tection d\'Intrusion - Mod√®le de simulation')

st.markdown("<h3 style='color: #1F4E79;'>Saisie des Donn√©es au format JSON</h3>", unsafe_allow_html=True)

# JSON editor avec valeurs par d√©faut 
example_json = json.dumps(example_values, indent=4)
st.markdown(f"**Exemple de format JSON attendu :**\n```json\n{example_json}\n```")

data_json = st.text_area("Entrez vos donn√©es au format JSON ici:", json.dumps(default_values, indent=4))

try:
    data_dict = json.loads(data_json)
    for key, value in default_values.items():
        if key not in data_dict:
            data_dict[key] = value
    
    st.write("Donn√©es saisies :", data_dict)
    
    if st.button('Faire une pr√©diction'):
        predictions = make_prediction(data_dict, scaler, encoder, model)
        threshold = 0.4
        prediction_label = "Intrusion probable" if predictions[0] >= threshold else "Intrusion peu probable"
        st.write(f"Pr√©diction : {prediction_label} (Score: {predictions[0]:.4f})")
        st.markdown("**Plus votre score se rapproche de 1, plus l'intrusion est probable.** Le seuil a √©t√© fix√© √† 0,4 afin d'√©viter au maximum les faux n√©gatifs. Plus votre score est proche de 0, plus le risque qu'une intrusion soit en cours est faible.")
except json.JSONDecodeError:
    st.error("Le format JSON est invalide. Veuillez corriger les erreurs et r√©essayer.")

st.markdown("<h2 style='text-align: center; font-weight: bold;'>Merci de votre passage sur cette application !</h2>", unsafe_allow_html=True)

st.markdown("<p style='color: #4682B4; font-style: italic;'>Application, dashboard et mod√®le r√©alis√©s par Marine Fruitier en 2024.</p>", unsafe_allow_html=True)

